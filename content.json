{"pages":[{"title":"About","text":"I’m James","link":"/about/index.html"},{"title":"","text":"Static Chart Binance BTCUSDT CHART","link":"/forex/index.html"},{"title":"About","text":"I’m James","link":"/forex/index1.html"},{"title":"","text":"//1. Define chart properties //2. Create chart with defined properites and bind it to the DOM element //3. Add the CandleStick Series //4. Set the data and render const log = console.log; const chartProperties ={ width:1500, height:600, timeScale:{ timeVisible:true, secondsVisible:false, } } const domElement = document.getElementById('tvchart'); const chart = LightweightCharts.createChart(domElement, chartProperties); const candleSeries = chart.addCandlestickSeries(); fetch('https://api.binance.com//api/v3/klines?symbol=BTCUSDT&interval=1m&limit=1000') .then(res => res.json()) .then(data => { const cdata = data.map(d => { return {time:d[0]/1000, open:parseFloat(d[1]), high:parseFloat(d[2]), low:parseFloat(d[3]), close:parseFloat(d[4])} }); candleSeries.setData(cdata); }) .catch(err => log(err))","link":"/forex/index.js"},{"title":"About","text":"Coming soon","link":"/photography/index.html"}],"posts":[{"title":"Diagnosing COVID-19 using Chest X-Rays","text":"In this article, I will be discussing how a Resnet architecture can be used to classify a dataset containing chest X-rays of patients who have COVID-19, pneumonia or are healthy. The spread of coronavirus throughout the world has happened at an unprecedented rate, shutting down entire countries and crippling economies. Production of testing equipment is often very limited and the global community would undoubtedly benefit from having alternative ways to diagnosing COVID-19. Currently, there is a very limited amount of data about Coronavirus cases, the main source I will be using for this article is Synthetaic which has collated data from COVID-NET and Image Data Collection. Due to the rapid pace which new COVID-19 data is being collected and the pace at which the Coronavirus literature is moving, I will be regularly updating my model and this article as more information becomes available. Using standard Coronavirus testing methods the estimated false negative rate is around 10%, the aim for this project is to help provide a system for distinguishing between pneumonia and COVID-19 with a high rate of success. Note: A link to my GitHub containing the code is at the bottom ModelFor this task, we will be using a Convolutional Neural Network(CNN) with the Resnet50 architecture, due to time constraints and a lack of data we will be using pre-trained weights gained from training this model on the ImageNet dataset. The data we will be using belongs to 3 classes: Uninfected, Infected or Pneumonia. I will be using the fastai library which is a deep learning framework built using PyTorch. Firstly, we create a DataBunch using default transformations and size of 224. 1234src = ImageList.from_folder(path).split_by_rand_pct(0.2).label_from_folder()tfms = get_transforms() data = src.transform(tfms=get_transforms, size=224, resize_method=ResizeMethod.SQUISH).databunch(bs=bs, num_workers=4).normalize() Images from the training set The Images we will be processing look like the images above, these images have already had transformations applied to them. Some of the transformations include: flipping the image horizontally rotating the image by up to 10 degrees Zooming into the image Random lighting and contrast changes Applying a random warp These transforms are essential as they help the model to generalise to images not contained with the training set, as well as helping to prevent the model overfitting. 1learn = cnn_learner(data, models.resnet50, metrics=error_rate) Next, we create a cnn_learner, this is inbuilt into fastai to allow easy implementation of convolutional neural networks. We also specify our model architecture to be resnet50, by default fast.ai will use transfer learning. Transfer learning is where we train the weights using another dataset and then we reuse those weights are starting values for our model whilst training on our dataset. Generally, the earlier layers in a CNN are used for detecting simple features such as edges, these features are very common are likely to be encountered in almost any image you come across. The image below is a visualization of an early layer within a CNN, this gives us a good intuition of why transfer learning is effective; most of the weights can be heavily reused throughout the network, allowing us to converge to an answer quickly with less data. Visualisation of a filter in an early layer of a CNN Training: Stage 1For this model, we will go through several rounds of training. Throughout the training process, we will be using several regularization techniques: weight decay, momentum and batch normalization. Firstly, we freeze the weights of the model and will only allow a few layers at the end of the model to be adjusted. This gives a very good accuracy of over 91% on the training set in just 5 epochs! Training the CNN with a learning rate of 0.002 Next, we will unfreeze the model and train all the layers for 5 epochs again. We will be using discriminative learning rates, this is where the learning rate will be lower in earlier layers, the reason for this is earlier layers have features which will not need to be changed very much (The pre-trained values from ImageNet are already very good values for this part of the network). Here the earlier layers will use a learning rate of 0.000001 whilst the later layers will use a learning rate of 0.0004. This gives us an even better accuracy of 93%. Training the CNN with discriminative learning rates Training: Stage 2Next, we will use another amazing tool called progressive resizing. Originally we were using images of size 224 to feed into our model, here we will feed in images of size 448. This allows our model to learn details about the training set and thus improve its performance. We also repeat the process of first training the model with the weights frozen and then unfreezing the weights, training in total for another 10 epochs. We can see our final model had an accuracy of over 95% on the training set!! Evaluating on the test setConfusion Matrix Our model has a weighted f1-score of 0.974 an accuracy rate of 97.4% on the test set. Furthermore correctly classified all the cases of Coronavirus; due to the lack of data, it is hard to draw any solid conclusions, however, our model managed to distinguished 10 COVID-19 x-rays from over 600 pneumonia x-rays. On the 22nd of March, Linda Wang and Alexander Wong published a paper detailing COVID-Net, which was described as, *”A Tailored Deep Convolutional Neural Network Design for Detection of COVID-19 Cases from Chest Radiography Images”* Predictions from COVID-Net The picture above shows the predictions from COVID-Net, we can see that COVID-Net correctly classified 8/10 COVID-19 x-rays whereas our model correctly classified 10/10 x-rays; it is worth that due to the incredibly small sample size this is not conclusive evidence that our model outperforms COVID-Net. It is also worth noting our test set contained a much larger sample of patients who are healthy or have pneumonia whilst still containing the same amount of COVID-19 patients AI has already undoubtedly proven itself as an invaluable tool to help improve the healthcare industry, however, unproven models such as this one should not be used for any medical diagnostics. Fun fact: All the training for this model cost me under $2 using Microsoft azure! Link to the source code in my GitHub","link":"/2020/04/15/Diagnosing-COVID-19-using-Chest-X-Rays/"},{"title":"What is a Convolutional Neural Network(CNN)?","text":"Convolutional neural networks have already been unknowingly influencing your life, their applications range from facial recognition to detecting deforestation from satellite images. In this article, I am going to show you how powerful of a tool Convolutional Neural Networks are, and how they learn. In abstract terms, A CNN is a function which has an image as its input and outputs what it thinks the image is. Inside this function, there are values called parameters which we get to choose the value of; our aim is to try and choose these values, these parameters such that our function correctly predicts the breed as much as possible. For this example say we have 1000 images of 5 different breeds of dog, evenly split. Our model will then be used to predict what breed of dog each image is. What our model is outputting is 10 values, these values are the probability of what breed it thinks the input image is, Here our model has predicted with a certainty of 80% that the image is a Cockapoo, and with a 10% certainty that it’s a Cavachon. Our model will then pick the highest value as it’s prediction. On the other hand, we can have an example where our model is very uncertain, Here our model has predicted with a certainty of 50% that the image is a Cockapoo, but has also predicted with a 45% certainty that it’s a Cavachon. There is alot more ambiguity in the latter example, however, as we currently see it both examples would give identical answers. Our aim here onwards will be to try and get the correct prediction’s value as close to 1 as possible and all the other values as close to 0 as possible. How they learnFirstly, I’ll need to introduce the term “cost function” from the deep learning literature.A cost function is a way of measuring how well we are doing at getting the probabilities in the diagrams above correct. It measures how close the correct probability is to 1 and how close the other probabilities are to 0. The value produced by the cost function is called the loss. The smaller the value of the cost function the better, and conversely the larger the value of the cost function the worse we are doing. So in order to make our function very good at predicting dog breeds, we need to minimize the value of our cost function. Gradient descent visualised: 120 mins Here we have a diagram, the vertical axis is the value given by our cost function and the others are the values we get to pick, called parameters. Our aim is to minimise the value given by our cost function, on this gram that corresponds to finding the values of w0 and w1 which give the global minimum for the loss. Given that we start at a random point on the graph how can we find our way down to the global minimum? Imagine you are standing on the slope of a valley, and you are trying to find your way to the bottom of the valley, but are blindfolded. What you can do is take a step in the downwards direction, We find the slope, also called gradient and take a step in the downwards direction So that’s all we’re doing here, we take a point on the graph and then take a step in the downward direction, then keep repeating this process until we’re at the minimum point. This also has a fancy name called gradient descent. So here we have 2 parameters w0 &amp; w1, and we’ve found the value for these which mean our function will correctly predict the breed of dog as much as possible. When our program is learning, all it’s doing exactly what we’ve described, the only difference is we have 2 parameters here, and in a real Convolutional Neural network you could easily have over 1 million, but it’s doing the exact same thing.How A CNNs different to a normal NNThe difference is that have something called kernels, which can also be called feature detectors because that’s exactly what they do. Our feature detector is scanned across the entire image*insert animation * Before we were talking about how the model learns and all it’s doing is choosing the best parameters, the best values inside the model. But where do these values actually fit in with the model? They’re actually the values in this feature detector!! explain elementwise multiplication with diagramgive vertical edge example Instead of having just one feature detector in the first layer, we might have 500 feature detectors.This means there are 500 different filters looking for different features in the image. The beauty of it is that we don’t need to specify the features the program needs to look for. What the kernels can tell us about the learning: layer 20; layer 30Layer 40 Image classification is the task of taking an input image, in the form of its raw pixels and outputting a class which it thinks the image belongs to. The core building block of a convolutional neural network is a convolutional layer. Several of these are stacked one after each other. The main aim of convolutions is to extract features such as edges and corners from the input, as you go deeper into then network the complexity of these features increases","link":"/2020/05/20/What-the-heck-is-a-Convolutional-Neural-Network-CNN/"},{"title":"Backtest 1","text":"GBPUSD 1:55","link":"/2020/08/03/backtest1/"},{"title":"Trade 1","text":"EURUSD 1:47 Remarks: London Open","link":"/2020/08/03/live1/"},{"title":"Trade 2","text":"GBPUSD 1:31, 1:67 Remarks: London Open","link":"/2020/08/03/live2/"}],"tags":[{"name":"Backtesting","slug":"Backtesting","link":"/tags/Backtesting/"},{"name":"GBPUSD","slug":"GBPUSD","link":"/tags/GBPUSD/"},{"name":"Live","slug":"Live","link":"/tags/Live/"},{"name":"EURUSD","slug":"EURUSD","link":"/tags/EURUSD/"},{"name":"LDN OPEN","slug":"LDN-OPEN","link":"/tags/LDN-OPEN/"}],"categories":[{"name":"Backtesting","slug":"Backtesting","link":"/categories/Backtesting/"},{"name":"GBPUSD","slug":"Backtesting/GBPUSD","link":"/categories/Backtesting/GBPUSD/"},{"name":"Live","slug":"Live","link":"/categories/Live/"},{"name":"EURUSD","slug":"Live/EURUSD","link":"/categories/Live/EURUSD/"},{"name":"GBPUSD","slug":"Live/GBPUSD","link":"/categories/Live/GBPUSD/"}]}